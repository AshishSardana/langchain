{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trustworthy Language Model\n",
    "\n",
    "Cleanlab’s TLM provides a trustworthiness score for every LLM output to catch hallucinations.\n",
    "\n",
    "This notebook shows how to use TLM and trustworthiness score.\n",
    "\n",
    "TLM is a more reliable LLM that gives high-quality outputs and indicates when it is unsure of the answer to a question, making it suitable for applications where unchecked hallucinations are a show-stopper.\n",
    "Trustworthiness score quantifies how confident you can be that the response is good (higher values indicate greater trustworthiness). These scores combine estimates of both aleatoric and epistemic uncertainty to provide an overall gauge of trustworthiness.\n",
    "\n",
    "Learn about using TLM via Cleanlab's [quickstart tutorial](https://help.cleanlab.ai/tutorials/tlm/), [blog](https://cleanlab.ai/blog/trustworthy-language-model/), and [API documentation](https://help.cleanlab.ai/reference/python/trustworthy_language_model/).\n",
    "\n",
    "Visit https://app.cleanlab.ai and sign up to get a free API key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install langchain community package to use the integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import TrustworthyLanguageModel\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Environment API Key\n",
    "Make sure to get your free API key from Cleanlab. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set api key in env or in tlm\n",
    "# import os\n",
    "# os.environ[\"CLEANLAB_API_KEY\"] = \"your api key\"\n",
    "\n",
    "tlm = TrustworthyLanguageModel(api_key=\"your_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = tlm.generate([\"Who is Paul Graham?\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.generations[0][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also get the trustworthiness score of the above response in the `trustworthiness_score` attribute. TLM automatically computes this score for all the <prompt, response> pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.generations[0][0].generation_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high score indicates that LLM's response can be trusted. Let's take another example here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = tlm.generate(\n",
    "    \"What was the horsepower of the first automobile engine used in a commercial truck in the United States?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.generations[0][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.generations[0][0].generation_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A low score indicates that the LLM's response shouldn't be trusted.\n",
    "\n",
    "From these 2 straightforward examples, we can observe that the LLM's responses with the highest scores are direct, accurate, and appropriately detailed.<br />\n",
    "On the other hand, LLM's responses with low trustworthiness score convey unhelpful or factually inaccurate answers, sometimes referred to as hallucinations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Async\n",
    "\n",
    "We can also use TLM asynchronously to allow non-blocking concurrent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = tlm.agenerate([\"Explain why saturn is round in only 100 words?\"], stop=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advance use of TLM\n",
    "\n",
    "### Configurations\n",
    "\n",
    "TLM can be configured with the following options:\n",
    "- **model**: underlying LLM to use\n",
    "- **max_tokens**: maximum number of tokens to generate in the response\n",
    "- **num_candidate_responses**: number of alternative candidate responses internally generated by TLM\n",
    "- **num_consistency_samples**: amount of internal sampling to evaluate LLM-response-consistency\n",
    "- **use_self_reflection**: whether the LLM is asked to self-reflect upon the response it generated and self-evaluate this response\n",
    "- **log**: specify additional metadata to return. include “explanation” here to get explanations of why a response is scored with low trustworthiness\n",
    "\n",
    "These configurations are passed as a dictionary to the `TrustworthyLanguageModel` object during initialization. <br />\n",
    "More details about these options can be referred from [Cleanlab's API documentation](https://help.cleanlab.ai/reference/python/trustworthy_language_model/#class-tlmoptions) and a few use-cases of these options are explored in [this notebook](https://help.cleanlab.ai/tutorials/tlm/#advanced-tlm-usage).\n",
    "\n",
    "Let's consider an example where the application requires `gpt-4` model with `128` output tokens. <br>\n",
    "We'll also set the `quality_preset` to \"best\" to get a higher-quality response compared to the default \"medium\" preset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"model\": \"gpt-4\",\n",
    "    \"max_tokens\": 128,\n",
    "}\n",
    "tlm = TrustworthyLanguageModel(api_key=\"your_api_key\", quality_preset=\"best\", options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = tlm.generate(\"Who is Paul Graham?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.generations[0][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand why the TLM estimated low trustworthiness for the previous horsepower related question, specify the \"explanation\" flag when initializing the TLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"log\": [\"explanation\"],\n",
    "}\n",
    "tlm = TrustworthyLanguageModel(api_key=\"your_api_key\", options=options)\n",
    "\n",
    "resp = tlm.generate(\n",
    "    \"What was the horsepower of the first automobile engine used in a commercial truck in the United States?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.generations[0][0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp.generations[0][0].generation_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating trustworthiness in existing pipeline\n",
    "\n",
    "You can just use TLM's trustworthiness score in an existing custom-built chain (using any other LLM generator, streaming or not). <br>\n",
    "To achieve this, you can use the `get_trustworthiness_score` method from the TLM object passing in both the prompt (with system, user, context messages) and the response.\n",
    "\n",
    "Let's consider an example where you want to log the untrustworthy responses from the LLM in a chain. <br>\n",
    "In this case, we'd define a callback that triggers when the LLM finishes generating response.\n",
    "\n",
    "Here's an example of a simple chain with TrustworthyLanguageModel as a callback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import BaseCallbackHandler\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom callback handler\n",
    "class TrustworthinessScoreCallback(BaseCallbackHandler):\n",
    "    # We get the response after LLM ends, hence the callback executes at this stage\n",
    "    def on_llm_end(self, response, **kwargs):\n",
    "        # Extract the prompt and response\n",
    "        prompt = kwargs.get('prompt', '')\n",
    "        # When response object is LLMResult, which is the return object type for most LLMs\n",
    "        response_text = response.generations[0][0].text\n",
    "\n",
    "        # Call trustworthiness score method, and extract the score\n",
    "        score = tlm.get_trustworthiness_score(prompt, response_text)\n",
    "\n",
    "        # Log the score\n",
    "        # This can be replaced with any action that the application requires\n",
    "        if score < 0.5:\n",
    "            logging.info(f\"The response can't be trusted. Truswrothiness score is {score}\")\n",
    "        else:\n",
    "            logging.info(f\"Trustable response with score {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Querying TLM... 100%|██████████|\n",
      "INFO:root:Trustable response with score 0.5547666663627023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='The answer is 4.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 20, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-20c39865-c901-4287-b367-f2a1adbaf560-0' usage_metadata={'input_tokens': 20, 'output_tokens': 6, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key='<your-api-key>')\n",
    "# Basic prompt template\n",
    "prompt_template = ChatPromptTemplate.from_template(\"What is the answer to {question}?\")\n",
    "# Create an instance of the callback\n",
    "trustworthiness_callback = TrustworthinessScoreCallback()\n",
    "# Attach callback to the LLM\n",
    "llm.callbacks = [trustworthiness_callback]\n",
    "# Create a simple chain\n",
    "chain = (\n",
    "    prompt_template | llm\n",
    ")\n",
    "\n",
    "# Run chain with a question\n",
    "result = chain.invoke({\"question\": \"What is 2 + 2?\"})\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a0a0263b650d907a3bfe41c0f8d6a63a071b884df3cfdc1579f00cdc1aed6b03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
